{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad42a5a7-d678-49fa-9a3e-481438893459",
   "metadata": {},
   "source": [
    "## ViT train & infer"
   ]
  },
  {
   "cell_type": "code",
   "id": "46a3448c-06fe-4314-8ded-9753f54f99db",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "419e3cf8-a902-4a35-bebe-c1f69ff6e5e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%time\n",
    "!python train_CLIP_ViT_pairwise.py --model_name 'openai/clip-vit-large-patch14-336' --train_data_file 'data/train_vit_pairwise.json' --test_data_file 'data/test_vit_pairwise.json' \\\n",
    "--image_dir 'data/imgs' --max_epoch 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8ca3454-7895-4e11-8fe8-03f8760fee42",
   "metadata": {
    "tags": []
   },
   "source": [
    "%time\n",
    "!python infer_Clip_ViT_pairwise.py  --model_name 'vit_pairwise_clip_model/model.pth' --test_data_file 'data/test_vit.json' --image_dir 'data/imgs' --save_path 'vit_pairwise_clip_model'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c30d6a3f-96d4-421d-9912-d5b5ab29d50c",
   "metadata": {
    "tags": []
   },
   "source": [
    "%time\n",
    "!python train_Clip_ViT_pairwise_emb.py --model_name 'openai/clip-vit-large-patch14-336' --train_data_file 'data/train_vit_pairwise_text.json' --test_data_file 'data/test_vit_pairwise_text.json' \\\n",
    "--image_dir 'data/imgs' --max_epoch 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0dd82b73-5c8d-4839-910d-d377927ad9a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "%time\n",
    "!python infer_Clip_ViT_pairwise_emb.py  --model_name 'vit_pairwise_model_emb/model.pth' --test_data_file 'data/test_vit_text.json' --image_dir 'data/imgs' "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af13494d-6aaa-4838-afe0-162d6affb0ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(213.89/287*10000)\n",
    "213.89/287*10000*2000/60/60*0.736"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3e9d975b-d9c3-4665-8387-253e343ce398",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "id": "ea3206af-c29c-4982-8bbe-e065a3d56b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "pred=pd.read_csv('vit_pairwise_clip_model/pred.csv')\n",
    "pred.head()\n",
    "pp=[1 if i>0.5 else 0 for i in pred['predict'].values]\n",
    "ll=[int(i) for i in pred['label'].values]\n",
    "print(classification_report(ll, pp))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d57c120-e5cd-44b9-a0e2-05fa8f9f66c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "!python eval.py --data_path 'vit_pairwise_clip_model/pred_single_sample.csv'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "59954c10-fd82-4643-b81a-c44bad4cdc9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "pred=pd.read_csv('vit_pairwise_model_emb/pred.csv')\n",
    "pred.head()\n",
    "pp=[1 if i>0.5 else 0 for i in pred['predict'].values]\n",
    "ll=[int(i) for i in pred['label'].values]\n",
    "print(classification_report(ll, pp))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa8591e2-6328-4491-9f61-e5dee4f882af",
   "metadata": {
    "tags": []
   },
   "source": [
    "!python eval.py --data_path 'vit_pairwise_model_emb/pred_single_sample.csv'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c485c36-f4e2-4111-b726-54f41d9d72d2",
   "metadata": {},
   "source": [
    "## badcase analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "259e718f-c65f-4649-8c57-b8be59d9b139",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred=pd.read_csv('./vit_pairwise_clip_model/pred_single_sample.csv')\n",
    "pred['hotel_id']=[i.split('_')[0] for i in pred['image'].values]\n",
    "pred.sort_values('predict',ascending=False,inplace=True)\n",
    "\n",
    "dd=[]\n",
    "grouped=pred.groupby('hotel_id')\n",
    "for _,group in grouped:\n",
    "    group['pred_label']=[1]+[0]*(group.shape[0]-1)\n",
    "    dd.append(group)\n",
    "dd=pd.concat(dd)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(dd['label'].values, dd['pred_label'].values))\n",
    "\n",
    "\n",
    "dw=dd[dd['label']!=dd['pred_label']]\n",
    "ids=dw['hotel_id'].unique()\n",
    "from PIL import Image\n",
    "dw.head()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def resize_image(input_image_path,resize=512):\n",
    "    original_image = Image.open(input_image_path)\n",
    "    width, height = original_image.size\n",
    "\n",
    "    if width >= height:\n",
    "        new_width = resize\n",
    "        new_height = int((resize / width) * height)\n",
    "    else:\n",
    "        new_height = resize\n",
    "        new_width = int((resize / height) * width)\n",
    "\n",
    "    resized_image = original_image.resize((new_width, new_height))\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def combine_images(image1, image2,  title1, title2):\n",
    "    # 加载两张图片\n",
    "\n",
    "    # 创建新的图像，大小为两张图片宽度之和，高度取两张图片中高度较大的那个\n",
    "    new_width = image1.width + image2.width\n",
    "    new_height = max(image1.height, image2.height)\n",
    "    new_image = Image.new('RGB', (new_width, new_height))\n",
    "\n",
    "    # 在新图像上绘制两张图片\n",
    "    new_image.paste(image1, (0, 0))\n",
    "    new_image.paste(image2, (image1.width, 0))\n",
    "\n",
    "    # 添加标题\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "    font = ImageFont.load_default()\n",
    "    draw.text((10, 10), title1, fill=\"black\", font=font)\n",
    "    draw.text((image1.width + 10, 10), title2, fill=\"black\", font=font)\n",
    "\n",
    "    return new_image\n",
    "    \n",
    "for id in ids:\n",
    "    dwi=dw[dw['hotel_id']==id]\n",
    "    print(dwi)\n",
    "    for img,predict,label,hotel_id,pred in dwi.values:\n",
    "        if label==1:\n",
    "            label1=img\n",
    "        elif pred==1:\n",
    "            pred1=img\n",
    "    print('hotel_id:',id)\n",
    "    # print('label pic:')\n",
    "    img1=resize_image('data/imgs/'+label1)\n",
    "    # print('predict pic:') \n",
    "    img2=resize_image('data/imgs/'+pred1)\n",
    "    combine_images(img1, img2,  'groud truth', 'predict').show()\n",
    "    # print('-----------------------')\n",
    "    \n",
    "   "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4434f6c-9e46-4123-b3d3-3bb553ac2be1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "dr=dd[dd['label']==dd['pred_label']]\n",
    "ids=dr['hotel_id'].sample(10).unique()\n",
    "for id in ids:\n",
    "    dwi=dr[dr['hotel_id']==id]\n",
    "    if sum(dwi['label'].values)==0:\n",
    "        continue\n",
    "    print(dwi)\n",
    "    for img,predict,label,hotel_id,pred in dwi.values:\n",
    "        if label==1:\n",
    "            label1=img\n",
    "        if pred==1:\n",
    "            pred1=img\n",
    "    print('hotel_id:',id)\n",
    "    # print('label pic:')\n",
    "    img1=resize_image('../data/imgs/'+label1).show()\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0233412-89df-4c1e-8e88-68cfb4667296",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e533c25-712d-4dcf-b55f-e9a25962bf37",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
